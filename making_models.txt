=== 
0. PREREQUISITE  
- SRILM binaries must be in PATH. (ngram-count and ngram) 
- Perl 5.8 or later needed.  
- Python 2.x needed by the sentence splitter. (Splitta, in /splitta) 

=== 
1. Unpack (the selected) GigaWord target gz files, and run splitta to
do tokenization & sentence splitting. This will form your corpus. 

Commands to run: 
> perl gzset_runner.pl [list of gigaword gz file] 

Note: output folder is defined in the script. For now, let's assume
this is "./models/document/". (actual may differ). This process will
take some time, according to the corpus size. 

===
2. Generate "collection" LM on all of the "story" (actual news
article) files.  

Commands to run: 
1) > perl cat_all_story.pl ./models/document > ./models/collection/collection.txt
2) > ngram-count -text ./models/collection/collection.txt -lm ./models/collection/collection.model -write-binary-lm 

Note: 1) generates single big collection text of news articles,for
      SRILM ngram modeller. 2) runs SRILM ngram model on the big text,
      and saves the resulting model on output/collection/collection.model
Note: If you have use some other options (like order n) for LM, 
      those should also be reflected on the next step. 

=== 

3. Generate "per document" LM on each of the "story". 

Commands to run: 
> perl perstory_runner.pl ./models/document 

Note: The model files (*.model) will be generated in the same
directory where the story (news article, *.story) file is located,
with the same name (*.story.model). (as binary SRILM ngram model) 
Note: This also takes some time, according to the corpus size. 

===
4. Now the model files are ready. Collection-wide model on
/models/collection/collection.model, and per-document models are at
/models/document/[newsfile].model 

Time to index them for fast calculation. 

Command to run: 
> perl indexing.pl ./models/document

Note: this will index all news documents (*.story) within the given
dir and its direct sub dirs, with Plucene (lucene perl implementation) 
Note: the resulting index will be stored in ./models_index. (This dir 
can be changed within the script, but in that case, you should also
change the global DOCUMENT_INDEX_DIR in proto_condprob.pm. 

NOTE: If you want to keep multiple indexes --- rename the default
models_index into something else, and pass this path to the index
using methods. In that case, you have to pass the path (full arguments
for P_t and P_t_h index methods, and no longer rely on default index
paths). 

===
5. Done. 



See next section (calc_cond_prob.txt?) for how to call the scripts 
that uses the models. 

